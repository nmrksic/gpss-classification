\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\reset@newl@bel
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Bayesian Machine Learning in the context of Data Science}{1}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contribution}{1}{section.1.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Gaussian Processes}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The Role of Kernels for Gaussian Processes}{2}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gaussian Process Classification}{2}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}The Laplace Approximation to Marginal Likelihood}{2}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Expectation Propagation}{2}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Variational Bayes}{2}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{3}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Kernel learning}{3}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Kernel structure discovery for regression}{3}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Additive Gaussian Processes}{4}{section.3.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Kernel Structure Discovery for GP Classification}{5}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Defining the Kernel Grammar}{5}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}The Search Operators}{5}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Model selection}{5}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Optimising the Hyperparameters}{5}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Overfitting}{6}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Guiding the Structure Search}{6}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Bayesian and Akaike Information Criteria}{6}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}The Number of Effective Hyperparameters}{6}{subsection.4.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Cross-validated training accuracy}{7}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Adapting the likelihood function}{7}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Dealing with Outliers}{7}{subsection.4.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Providing Interpretability}{8}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Pima}{8}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Liver}{9}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Heart}{9}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Visualising the kernel decomposition}{9}{subsection.4.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Bayesian Model Averaging}{9}{section.4.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}BMA for Predictive Performance}{9}{subsection.4.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}BMA for Model Selection}{10}{subsection.4.7.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Evaluation}{11}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Experiments with Synthetic Data}{11}{section.5.1}}
\newlabel{tbl:synthetic}{{5.1}{12}{Experiments with Synthetic Data\relax }{section.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Adding Salt and Pepper Noise}{12}{subsection.5.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces { True kernel: $ \textsc  {SE}_1 + \textsc  {SE}_2 + \textsc  {SE}_3$, $D$ = 3. }}}{13}{table.5.1}}
\newlabel{tbl:synthetic1}{{5.1}{13}{{ True kernel: $ \SE _1 + \SE _2 + \SE _3$, $D$ = 3. }\relax }{table.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces { True kernel: $ \textsc  {SE}_1 + \textsc  {SE}_2 \times \textsc  {SE}_3 + \textsc  {SE}_4$, $D$ = 4. }}}{14}{table.5.2}}
\newlabel{tbl:synthetic2}{{5.2}{14}{{ True kernel: $ \SE _1 + \SE _2 \times \SE _3 + \SE _4$, $D$ = 4. }\relax }{table.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces {True kernel: $ \textsc  {SE}_1 + \textsc  {SE}_3 \times \textsc  {SE}_7 + \textsc  {SE}_{10}$, $D$ = 10. }}}{14}{table.5.3}}
\newlabel{tbl:synthetic3}{{5.3}{14}{{True kernel: $ \SE _1 + \SE _3 \times \SE _7 + \SE _{10}$, $D$ = 10. }\relax }{table.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces { True kernel: $\textsc  {SE}_1 + \textsc  {SE}_3 \times \textsc  {SE}_5 \times \textsc  {SE}_7 + \textsc  {SE}_{9}$, $D$ = 10. }}}{15}{table.5.4}}
\newlabel{tbl:synthetic4}{{5.4}{15}{{ True kernel: $\SE _1 + \SE _3 \times \SE _5 \times \SE _7 + \SE _{9}$, $D$ = 10. }\relax }{table.5.4}{}}
\citation{duvenaud2011additive11}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiments on Real World Data Sets}{16}{section.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces {\relax \fontsize  {10.95}{13.6}\selectfont  \abovedisplayskip 11\p@ plus3\p@ minus6\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6.5\p@ plus3.5\p@ minus3\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 9\p@ plus3\p@ minus5\p@ \parsep 4.5\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Classification Percent Error }}}{16}{table.5.5}}
\newlabel{tbl:Classification Percent Error}{{5.5}{16}{{\small Classification Percent Error }\relax }{table.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Visualisation}{17}{section.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Summary and Conclusions}{18}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Further Work}{18}{section.6.1}}
\bibstyle{unsrt}
\bibdata{refs}
\bibcite{duvenaud2011additive11}{{1}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
