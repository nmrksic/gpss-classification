function [] = plotPosteriorDemo2( )

n = 300;
D = 3;

InitialiseRand(4);

% Genereate data from known underlying additive function
x = rand(n, D);
truefunc = @(x) ( sin(x(:,1) * 2) + cos(x(:,2) * 2) + x(:,3) * 2);
sigmoid = @(y) ( 1 ./ ( 1+ exp(-y)));
probs = sigmoid(truefunc(x));
y = probs > rand(n,1);   % Sampling from a Bernoulli for each y.
y = double(y);
y(y==0) = -1;

% Set up GP model.
inf = @infLaplace;
mean = @meanConst;
lik = @likErf;
encoder = [ 1;2;3 ]; % se2 + se6 * se5 * se3
cov = encodeKernel(encoder, D);

% Set up initial hypers.
Hyp.mean = 0.0;
Hyp.cov = [0 0 0 0 0 0];

% Optimize hypers
hypN = minimize(Hyp, @gp, -100, inf, mean, cov, lik, x, y);

% Unpack covariance function into additive components.
for i = 1:3
    encoder2 = [i];
    covStruct{i} = encodeKernel(encoder2, size(x, 2));
    Hyp2.cov =  hypN.cov( i*2-1 : i*2 );
    hypStruct{i}= Hyp2.cov;
end

% Plot approximate posterior decomposition of latent function.
[~, ~, ~, ~, ~, post] = gp(Hyp, inf, mean, cov, lik, x, y, x, y);
plot_additive_decomp(x, y, post, covStruct, hypStruct, false, true, 'images/classification-decomp');

